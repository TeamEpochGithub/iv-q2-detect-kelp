{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-05T14:11:22.484172700Z",
     "start_time": "2024-01-05T14:11:22.337786700Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "test = \"../test\"\n",
    "os.makedirs(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T14:11:22.513690400Z",
     "start_time": "2024-01-05T14:11:22.341127300Z"
    }
   },
   "id": "b43527095e7be3c6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def load_data(paths):\n",
    "    # Get a list of all files in the directory (X_train, y_train, X_test)\n",
    "    file_list = [[file for file in os.listdir(paths) if file.endswith('.tif')] for paths in directory_paths]\n",
    "\n",
    "    # Sort the file list to ensure consistent order\n",
    "    file_list = [sorted(files) for files in file_list]\n",
    "\n",
    "    # Initialize an empty array to store the image data\n",
    "    X_train, y_train, X_test = [], [], []\n",
    "\n",
    "\n",
    "    # Iterate through the selected files\n",
    "    for X_train_name, y_train_name in zip(file_list[0], file_list[1]):\n",
    "        # Construct the full path to the file\n",
    "        X_train_path = os.path.join(paths[0], X_train_name)\n",
    "        y_train_path = os.path.join(paths[1], y_train_name)\n",
    "\n",
    "        # Open the raster file using rasterio\n",
    "        with rasterio.open(X_train_path) as src:\n",
    "            # Read the entire image data as a NumPy array\n",
    "            image_data = src.read()\n",
    "\n",
    "            # Append the image data to the array\n",
    "            X_train.append(image_data)\n",
    "\n",
    "        # Open the raster file using rasterio\n",
    "        with rasterio.open(y_train_path) as src:\n",
    "            # Read the entire image data as a NumPy array\n",
    "            image_data = src.read()\n",
    "\n",
    "            # Append the image data to the array\n",
    "            y_train.append(image_data)\n",
    "\n",
    "    for X_test_name in file_list[2]:\n",
    "        # Construct the full path to the file\n",
    "        X_test_path = os.path.join(paths[2], X_test_name)\n",
    "\n",
    "        with rasterio.open(X_test_path) as src:\n",
    "            # Read the entire image data as a NumPy array\n",
    "            image_data = src.read()\n",
    "\n",
    "            # Append the image data to the array\n",
    "            X_test.append(image_data)\n",
    "    # Convert the list of arrays to a single NumPy array\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    return X_train, y_train, X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T14:11:22.530261100Z",
     "start_time": "2024-01-05T14:11:22.343583900Z"
    }
   },
   "id": "f40766610f795b7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EmielW\\Epoch\\Competitions\\q2-detect-kelp\\venv\\Lib\\site-packages\\rasterio\\__init__.py:317: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "directory_paths = ['../../data/raw/train_satellite', '../../data/raw/train_kelp', '../../data/raw/test_satellite']\n",
    "\n",
    "X_train, y_train, X_test = load_data(directory_paths)\n",
    "\n",
    "print(\"Shape of the X_train array:\", X_train.shape)\n",
    "print(\"Shape of the y_train array:\", y_train.shape)\n",
    "print(\"Shape of the X_test array:\", X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-05T14:11:22.348244700Z"
    }
   },
   "id": "4e7eed21dc4d4dee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_list = [[file for file in os.listdir(paths) if file.endswith('.tif')] for paths in directory_paths]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a74cdb8e1077b857"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bands = [\"SWIR\", \"NIR\", \"Red\", \"Green\", \"Blue\", \"Cloud Mask\", \"Digital Elevation Map\"]\n",
    "\n",
    "metadata = pd.read_csv('../../data/raw/metadata_fTq0l2T.csv')\n",
    "metadata = metadata.sort_values(by=['in_train', 'filename'], ascending=[False, True])\n",
    "\n",
    "print(len(metadata))\n",
    "metadata.head()\n",
    "\n",
    "# Check for duplicate tile ids\n",
    "print(\"Number of unique tile ids:\", len(metadata['tile_id'].unique()))\n",
    "print(\"Number of unique tile filenames:\", len(metadata['filename'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "10bea88b5f82bf77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Apply a standardscaler on X_train and X_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape train and test\n",
    "X_train = X_train.reshape(-1, 7)\n",
    "X_test = X_test.reshape(-1, 7)\n",
    "\n",
    "# Fit and transform scaler on training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform test data\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "75d7d74968388710"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reshape train and test back\n",
    "X_train = X_train.reshape(-1, 7, y_train.shape[2], y_train.shape[3])\n",
    "X_test = X_test.reshape(-1, 7, y_train.shape[2], y_train.shape[3])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "13ba15dd64d8691"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert X_train, y_train, and X_test into tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f846dfccfcc5381"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from notebooks.submission.model import Model\n",
    "from notebooks.submission.blocks import SoftDiceLoss\n",
    "from notebooks.submission.unet import UNet2D\n",
    "\n",
    "#Prepare dataset with dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# COvert torch tensor to dataset\n",
    "\n",
    "class KelpDataset(Dataset):\n",
    "    \"\"\"Kelp dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (Tensor): Tensor of shape (N, C, H, W) containing the satellite images.\n",
    "            y (Tensor): Tensor of shape (N, C, H, W) containing the kelp mask.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            #Reshape X To (H,W,C)\n",
    "            X = X.permute(1,2,0)\n",
    "            y = y.permute(1,2,0)\n",
    "            X = self.transform(image=X.to('cpu').numpy())[\"image\"]\n",
    "            y = self.transform(image=y.to('cpu').numpy())[\"image\"]\n",
    "        return X, y\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f5fbc8c77e86deee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create train and validation dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_tensor, y_train_tensor, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3788a25682c2eac9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "# Create a dictionary of the transformations\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "#Create datasets\n",
    "train_dataset = KelpDataset(X_train, y_train,  transform=None)\n",
    "val_dataset = KelpDataset(X_val, y_val, transform=None)\n",
    "\n",
    "#Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b31d69da3143ea6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset = KelpDataset(X_test_tensor, torch.zeros(X_test_tensor.shape))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bf0175988da01230"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ded563a287c92d48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from notebooks.submission.metrics import jaccard_index, f1_score, LogNLLLoss\n",
    "from notebooks.submission.model import Model\n",
    "from notebooks.submission.DiceLoss import DiceLoss\n",
    "from torch.nn import BCELoss, MSELoss\n",
    "\n",
    "# Create model\n",
    "unet = UNet2D(in_channels=7, out_channels=2, conv_depths=(64, 128, 256))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "summary(unet.cuda(), (7, 256, 256))  \n",
    "loss = DiceLoss()\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=0.01)\n",
    "results_folder = 'models'\n",
    "\n",
    "model = Model(unet,loss, optimizer, results_folder, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "994f3f88fb02169f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fbaadb548b85a8e2"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4e01a48b3554d2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "model.fit_dataset(train_dataloader, n_epochs=10, n_batch=32, shuffle=True, val_dataset=val_dataloader, verbose=True, save_model=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "be2c25fbf053ff41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "88a86a7dd27734d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2d19937245c09eb9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from rasterio.plot import show\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def normalize_images(images_array: np.ndarray):\n",
    "    # Create an empty array to store the normalized image data\n",
    "    normalized_images_array = np.zeros(images_array.shape)\n",
    "\n",
    "    # Iterate through each band\n",
    "    for i in range(images_array.shape[1]):\n",
    "        # Get the band data\n",
    "        band = images_array[:, i, :, :]\n",
    "        # Set NaNs to 0 (Nan = -32768 in the original images)\n",
    "        # For band 0 to 4, normalize the band data to values between 0 and 1 by dividing by 65535\n",
    "        if i < 5:\n",
    "            band[band == -32768] = 0\n",
    "            normalized_band = band / 65535.0\n",
    "            #normalized_band = cv2.normalize(normalized_band, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "        # For band 5 do nothing\n",
    "        elif i == 5:\n",
    "            normalized_band = band\n",
    "        # For band 6, do normal normalization\n",
    "        elif i == 6:\n",
    "            band[band == -32768] = 0\n",
    "            normalized_band = band\n",
    "            #normalized_band = (band - np.min(band)) / (np.max(band) - np.min(band))\n",
    "\n",
    "        # Store the normalized band data\n",
    "        normalized_images_array[:, i, :, :] = normalized_band\n",
    "\n",
    "    return normalized_images_array\n",
    "\n",
    "\n",
    "def normalize_image(image: np.ndarray):\n",
    "    normalized_images_array = np.zeros(image.shape)\n",
    "    # Iterate through each band\n",
    "    for i in range(image.shape[0]):\n",
    "        # Get the band data\n",
    "        band = image[i, :, :]\n",
    "        # Set NaNs to 0 (Nan = -32768 in the original images)\n",
    "        # For band 0 to 4, normalize the band data to values between 0 and 1 by dividing by 65535\n",
    "        if i < 5:\n",
    "            band[band == -32768] = 0\n",
    "            normalized_band = band / 65535.0\n",
    "        # For band 5 do nothing\n",
    "        elif i == 5:\n",
    "            normalized_band = band\n",
    "        # For band 6, do normal normalization\n",
    "        elif i == 6:\n",
    "            band[band == -32768] = 0\n",
    "            normalized_band = band\n",
    "            #normalized_band = (band - np.min(band)) / (np.max(band) - np.min(band))\n",
    "\n",
    "        # Store the normalized band data\n",
    "        normalized_images_array[i, :, :] = normalized_band\n",
    "\n",
    "    return normalized_images_array\n",
    "\n",
    "\n",
    "def visualize_images(filenames: list, is_train=True, predictions=None):\n",
    "    # Create a 2x3 grid for image display\n",
    "    num_rows = len(filenames)\n",
    "    num_cols = 5\n",
    "\n",
    "    if is_train:\n",
    "        X_normed = normalize_images(X_train[filenames, :, :, :])\n",
    "    else:\n",
    "        X_normed = normalize_images(X_test[filenames, :, :, :])\n",
    "    # Normalize the images\n",
    "\n",
    "    # Create a figure and subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(80, num_rows * 20))\n",
    "\n",
    "    # Flatten the 2D array of subplots into a 1D array\n",
    "    axes = axes.flatten()\n",
    "    c = 0\n",
    "    cmap_mask = ListedColormap(['black', 'white'])\n",
    "    # Display each image in a subplot\n",
    "    for i in range(0, num_rows * num_cols, 5):\n",
    "        # Display the RGB image\n",
    "        show(X_normed[c, 2:5, :, :], ax=axes[i])\n",
    "        axes[i].set_title(\"RGB Image\")\n",
    "\n",
    "        # Display the SWIR, NIR, Red image\n",
    "        show(X_normed[c, 0:3, :, :], ax=axes[i + 1])\n",
    "        axes[i + 1].set_title(f\"SWIR, NIR, Red Image and file: {file_list[0][filenames[c]]}\")\n",
    "\n",
    "        # Display the Cloud mask band (5)\n",
    "\n",
    "        axes[i + 2].imshow(X_normed[c, 5, :, :], cmap=cmap_mask)\n",
    "        axes[i + 2].set_title(\"Cloud Mask\")\n",
    "\n",
    "        # Display the Digital Elevation Map band (6)\n",
    "        axes[i + 3].imshow(X_normed[c, 6, :, :], cmap='jet')\n",
    "        axes[i + 3].set_title(\"Digital Elevation Map\")\n",
    "\n",
    "        # Display the label\n",
    "        show(X_normed[c, 0:3, :, :], ax=axes[i + 4])\n",
    "        if is_train:\n",
    "            axes[i + 4].imshow(y_train[filenames[c]][0], cmap='jet', alpha=0.5 * (y_train[filenames[c]][0] > 0))\n",
    "        if predictions is not None:\n",
    "            axes[i + 4].imshow(predictions[c][1], cmap='jet', alpha=0.5 * (predictions[c][1] > 0.97))\n",
    "        axes[i + 4].set_title(\"Label\")\n",
    "        # Display the SWIR, NIR, Red image with the label\n",
    "        c += 1\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    if is_train:\n",
    "        plt.savefig(f'../../plots/images/predictions/visualize_images{str(filenames)}.png')\n",
    "    else:\n",
    "        plt.savefig(f'../../plots/images/predictions/visualize_images{str(filenames)}.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4f03360e00cde00f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load the best model from /models/best_model.pt with state dict\n",
    "model.net = torch.load(\"models/best_model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "24515c5fcf86c0fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test Predictions + Vis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc3b2e7ace9f9440"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_folder = '../../plots/images/predictions/masks-unet'\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "#Delete in the results folder\n",
    "for file in os.listdir(results_folder):\n",
    "    os.remove(os.path.join(results_folder, file))\n",
    "\n",
    "test_predictions = model.predict_dataset(test_dataloader, results_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fa8c1ca44ba2d5a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_images([0,1,2,3,4,5,6,7,8,9], is_train=False, predictions = test_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e4e704376c77374f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tune the threshold on all train data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "647bca1098b509b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "results_folder = '../../plots/images/all/masks-unet'\n",
    "#Create dataset from X_train_tensor and y_train_tensor\n",
    "all_dataset = KelpDataset(X_train_tensor, y_train_tensor)\n",
    "all_dataloader = DataLoader(all_dataset, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1dc44054e1255f52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_predictions = model.predict_dataset(all_dataloader, results_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5705118610b80d5b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dice_metric(inputs, targets, threshold=0.5, smooth=1.):\n",
    "        # comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        # inputs = F.sigmoid(inputs)\n",
    "\n",
    "\n",
    "        inputs = inputs.reshape(-1)\n",
    "        targets = targets.reshape(-1)\n",
    "        \n",
    "        inputs[inputs > threshold] = 1\n",
    "        inputs[inputs <= threshold] = 0\n",
    "        # Convert inputs to tensor\n",
    "        inputs = torch.from_numpy(inputs).float()\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return dice.item()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2a6c6086bde25fe7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "thresholds = []\n",
    "scores = []\n",
    "best_threshold = 0.5\n",
    "while i < 50:\n",
    "    #Set random threshold\n",
    "    threshold = np.random.uniform(0.0, 1)\n",
    "    dice = dice_metric(all_predictions[:,1,:,:], y_train_tensor, threshold=threshold)\n",
    "    print(f\"Dice score for threshold {threshold} is {dice}\")\n",
    "    if dice > best_threshold:\n",
    "        best_threshold = threshold\n",
    "    thresholds.append(threshold)\n",
    "    scores.append(dice)\n",
    "    i += 1\n",
    "\n",
    "print(f\"Best threshold is {best_threshold}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "91ceb6444a72b1a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plot the dice scores as a scatterplot\n",
    "import seaborn as sns\n",
    "sns.scatterplot(x=thresholds, y=scores)\n",
    "#Set x axis\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Dice Score\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c215d212976d8987"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cdfd3173e306d1b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Submission"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31d7b1290514470b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tifffile \n",
    "from pathlib import Path\n",
    "# Create a submission file of the predictions (store single-band TIF files with predictions of each image in test_predictions)\n",
    "loc = \"zip/\"\n",
    "#Create the dir\n",
    "if not os.path.exists(loc):\n",
    "    os.makedirs(loc)\n",
    "    \n",
    "    \n",
    "#Remove all files from zip\n",
    "for file in os.listdir(loc):\n",
    "    os.remove(os.path.join(loc, file))\n",
    "\n",
    "for i, (pred, filename) in tqdm(enumerate(zip(test_predictions, file_list[2]))):\n",
    "    files = filename.split(\"_\")\n",
    "    filename = files[0] + \"_kelp.tif\"\n",
    "    #Set replace values above 0.5 to be 1 and below 0.5 to be 0 of pred\n",
    "    pred[pred > best_threshold] = 1\n",
    "    pred[pred <= best_threshold] = 0\n",
    "    #Save the prediction as tiff file\n",
    "    #Threshold the \n",
    "    tifffile.imwrite(os.path.join(loc, filename), pred[1].reshape(1, pred.shape[1], pred.shape[2]))\n",
    "    \n",
    "#Create a zip file of all files in loc\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"submission.zip\", \"w\") as zipped:\n",
    "    files = Path(loc).rglob('*.tif') #get all files.\n",
    "    for file in files:\n",
    "        zipped.write(file, file.name)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d84f4dc2cc9029a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "788822c12182c90b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
